{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Deploy Hugging face `all-mpnet-base-v2` model - without model\n",
        "\n",
        "Deploy hugging face model - model is dynamicly loaded by endpoint\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Connect to Azure Machine Learning Workspace"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import required libraries\n",
        "from azure.ai.ml import MLClient\n",
        "from azure.ai.ml.entities import (\n",
        "    ManagedOnlineEndpoint,\n",
        "    ManagedOnlineDeployment,\n",
        "    Environment,\n",
        "    CodeConfiguration,\n",
        ")\n",
        "from azure.identity import DefaultAzureCredential"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# get a handle to the workspace\n",
        "\n",
        "ml_client = MLClient.from_config(credential=DefaultAzureCredential())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create the endpoint\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define an endpoint name\n",
        "\n",
        "\n",
        "import uuid\n",
        "endpoint_name = \"all-mpnet-base-\" + str(uuid.uuid4())[:4]\n",
        "\n",
        "endpoint = ManagedOnlineEndpoint(name=endpoint_name)\n",
        "\n",
        "endpoint = ml_client.begin_create_or_update(endpoint).result()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define the deployment\n",
        "\n",
        "A deployment is a set of resources required for hosting the model that does the actual inferencing.\n",
        "\n",
        "This also creates a one-off enviroment based on an existing docker image and a conda file\n",
        "\n",
        "                          |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "deployment_name = \"get-embeddings\"\n",
        "deployment = ManagedOnlineDeployment(\n",
        "    name=deployment_name,\n",
        "    endpoint_name=endpoint_name,\n",
        "    code_configuration=CodeConfiguration(\n",
        "        code=\"./src\", scoring_script=\"score.py\"\n",
        "    ),\n",
        "    environment=Environment(\n",
        "        image=\"mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:latest\",\n",
        "        conda_file=\"conda.yaml\",\n",
        "    ),\n",
        "    instance_type=\"Standard_DS3_v2\",\n",
        "    instance_count=1,\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create the deployment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "."
          ]
        }
      ],
      "source": [
        "deployment = ml_client.online_deployments.begin_create_or_update(deployment).result()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Assign traffic to the deployment\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "endpoint.traffic = {deployment_name: 100}\n",
        "endpoint = ml_client.begin_create_or_update(endpoint).result()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Get the endpoint URL\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "API_URI = endpoint.scoring_uri\n",
        "print(f\"API URI: {API_URI}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Check the endpoint on the deployment\n",
        "\n",
        "Go to https://aml.azure.com, find your **Endpoint** -> **Consume** and get the key.\n",
        "\n",
        "Create a `.env` file and put the following:\n",
        "\n",
        "```bash\n",
        "API_KEY=<<get api key from endpoint in aml>>\n",
        "API_URI=<<the API_URI you got above .. you can also get it from **Endpoint** -> **Consume** >> \n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Define get_embeddings "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import requests\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "\n",
        "\n",
        "API_KEY = os.getenv(\"API_KEY\")\n",
        "API_URI = os.getenv(\"API_URI\")\n",
        "\n",
        "\n",
        "def get_embeddings(data,url=API_URI,api_key=API_KEY):\n",
        "\n",
        "\n",
        "    # Replace this with the primary/secondary key, AMLToken, or Microsoft Entra ID token for the endpoint\n",
        "    \n",
        "    if not api_key:\n",
        "        raise Exception(\"A key should be provided to invoke the endpoint\")\n",
        "\n",
        "    headers = {'Content-Type': 'application/json', 'Authorization': 'Bearer ' + api_key}\n",
        "\n",
        "    response = requests.post(url, json=data, headers=headers)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        result = response.json()\n",
        "        return result\n",
        "    else:\n",
        "        print(\"The request failed with status code: \" + str(response.status_code))\n",
        "        print(response.headers)\n",
        "        print(response.text)\n",
        "        return None\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Test it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(get_embeddings({\"sentences\": \"Hello, World!\"}))"
      ]
    }
  ],
  "metadata": {
    "categories": [
      "SDK v2",
      "sdk",
      "python",
      "endpoints",
      "online",
      "managed"
    ],
    "description": {
      "description": "Use an online endpoint to deploy your model, so you don't have to create and manage the underlying infrastructure"
    },
    "kernelspec": {
      "display_name": "azureml_py310_sdkv2",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
